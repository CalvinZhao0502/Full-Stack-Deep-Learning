## Lecture 1 DL Fundamentals

### 1.1 Neural Networks

### 1.2 Universality

### 1.3 Learning Problems

### 1.4 Empirical Risk Minimization / Loss Functions

### 1.5 Gradient Descent

### 1.6 Backpropagation / Automatic Differentiation

### 1.7 Architectural Considerations (deep / conv / rnn)

### 1.8 CUDA / Cores of Compute

### 